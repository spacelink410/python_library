{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "- Импортируйте библиотеки pandas и numpy.\n",
    "- Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.\n",
    "- Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "- Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "- Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "- Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.711226005748496\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston['data']\n",
    "target = boston['target']\n",
    "feature_names = boston['feature_names']\n",
    "\n",
    "X = pd.DataFrame(data, columns = feature_names)\n",
    "Y = pd.DataFrame(target, columns = ['price'])\n",
    "\n",
    "#X.info()\n",
    "#Y.info()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.30, random_state=42)\n",
    "#print(X_train.head(10))\n",
    "#print(X_test.head(10))\n",
    "#print(Y_train.head(10))\n",
    "#print(Y_test.head(10))\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "check = pd.DataFrame({'Y_test': Y_test['price'], 'Y_pred': Y_pred.flatten()})\n",
    "#print(check.head(10))\n",
    "\n",
    "R2 = r2_score(check['Y_test'], check['Y_pred'])\n",
    "print(R2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "- Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "- Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "- Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy,так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "- Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "- Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87472606157312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)\n",
    "model.fit(X_train, Y_train.values[:, 0])\n",
    "\n",
    "Y_pred_2 = model.predict(X_test)\n",
    "check_2 = pd.DataFrame({'Y_test': Y_test['price'], 'Y_pred': Y_pred_2.flatten()})\n",
    "#print(check.head(10))\n",
    "\n",
    "R2_2 = r2_score(check_2['Y_test'], check_2['Y_pred'])\n",
    "print(R2_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Исходя из полученных данных модель model работает лучше, т.к. R2_2 ближе к 1, чем R2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3\n",
    "- Вызовите документацию для класса RandomForestRegressor, найдите информацию об атрибуте feature_importances_.\n",
    "- С помощью этого атрибута найдите сумму всех показателей важности, установите, какие два признака показывают наибольшую важность.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         importance\n",
      "feature            \n",
      "LSTAT      0.415847\n",
      "RM         0.402682\n",
      "DIS        0.063973\n",
      "CRIM       0.031676\n",
      "PTRATIO    0.018081\n",
      "AGE        0.014299\n",
      "NOX        0.014269\n",
      "B          0.012451\n",
      "TAX        0.011525\n",
      "INDUS      0.007138\n",
      "RAD        0.005281\n",
      "ZN         0.001543\n",
      "CHAS       0.001236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='feature'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEmCAYAAABs7FscAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjsklEQVR4nO3df5xWdZ338debQcIldENHIxFBRcldfkjDWJIp24ra5mJpKroWbkTciv20jd2973bLuztrKy0jkcyb6tbFtGhZI39Umpaag4kgiopEOVGpZEblDwY+9x/nDB4urpk5M9e5rmEO7+fjMQ+u8+N7Pt9rLuZzfc/3fM/3KCIwM7PyGtTfFTAzs/pyojczKzknejOzknOiNzMrOSd6M7OSc6I3Myu5wf1dgWr233//GDNmTH9Xw8xswLj//vufiYjmatt2y0Q/ZswYVq5c2d/VMDMbMCT9oqtt7roxMys5J3ozs5JzojczK7ndso/ezAaWrVu30t7ezgsvvNDfVSm9oUOHMmrUKPbaa6/cZZzozaxm7e3tDB8+nDFjxiCpv6tTWhHB5s2baW9vZ+zYsbnLuevGzGr2wgsvsN9++znJ15kk9ttvv16fOTnRm1khnOQboy+/Zyd6Mxvwjj322IbG27hxI9ddd11DY9ZiQPXRj1nw3V6X2Xjp39WhJmbWnb78rXanp7/ju+++u9B43eno6NiR6M8555yGxa2FW/RmNuC98pWvBOCOO+7g+OOP58wzz+SII45gwYIFXHvttbS2tjJhwgSeeOIJAGbPns28efM47rjjOOKII7jpppuA5FrD+eefz4QJEzj66KO5/fbbAViyZAnveMc7OPXUU5kxYwYLFizgrrvuYvLkyVx22WVs3LiR4447jilTpjBlypQdXzx33HEHJ5xwAmeccQbjx4/n3HPPpfOpfm1tbRx77LFMmjSJ1tZWtmzZwrZt2/jIRz7C1KlTmThxIldddVUhv58B1aI3M+vJgw8+yCOPPMKIESM49NBDmTNnDvfddx9f+MIXuOKKK7j88suBpPvlRz/6EU888QTTp09n/fr1LFy4EIA1a9awbt06ZsyYwWOPPQbAPffcw+rVqxkxYgR33HEHn/3sZ3d8Qfz5z3/mtttuY+jQoTz++OPMmjVrxzQuDzzwAGvXruU1r3kN06ZN4yc/+Qmtra2cddZZXH/99UydOpU//OEP7L333nz1q19l3333pa2tjRdffJFp06YxY8aMXo2wqcaJ3sxKZerUqYwcORKAww47jBkzZgAwYcKEHS10gDPPPJNBgwYxbtw4Dj30UNatW8ePf/xjLrroIgDGjx/PIYccsiPRn3jiiYwYMaJqzK1btzJ//nxWrVpFU1PTjjIAra2tjBo1CoDJkyezceNG9t13X0aOHMnUqVMB2GeffQC49dZbWb16NTfeeCMAzz33HI8//nhjEr2kk4EvAE3A1RFxaRf7TQXuBc6KiBt7U9bMrAiveMUrdrweNGjQjuVBgwbR0dGxY1vl6BVJO7pVqhk2bFiX2y677DIOPPBAHnzwQbZv387QoUOr1qepqYmOjg4iouromYjgiiuu4KSTTurmHfZej330kpqAhcApwFHALElHdbHfp4FbelvWzKzRbrjhBrZv384TTzzBhg0bOPLII3nTm97EtddeC8Bjjz3GL3/5S4488shdyg4fPpwtW7bsWH7uuecYOXIkgwYN4hvf+Abbtm3rNvb48ePZtGkTbW1tAGzZsoWOjg5OOukkrrzySrZu3bqjDn/6059qfq95WvStwPqI2AAgaSkwE3i4Yr+LgG8BU/tQ1sysoY488kiOP/54fvvb37Jo0SKGDh3KBRdcwLx585gwYQKDBw9myZIlO7XIO02cOJHBgwczadIkZs+ezQUXXMDpp5/ODTfcwPTp07tt/QMMGTKE66+/nosuuojnn3+evffem+9///vMmTOHjRs3MmXKFCKC5uZmvvOd79T8XtXdqQqApDOAkyNiTrp8HnBMRMzP7HMQcB3wN8BXgZsi4sY8ZatpaWmJavPRN2p4pYdxmvXOI488wmtf+9r+rkZus2fP5q1vfStnnHFGf1elT6r9viXdHxEt1fbPM7yy2m1Yld8OlwMfjYjK85U8ZZMdpbmSVkpa+fTTT+eolpmZ5ZGn66YdODizPArYVLFPC7A0vbiwP/AWSR05ywIQEYuBxZC06PNU3sysL5YsWdLfVWioPIm+DRgnaSzwK+BsYKfbwSJix9gfSUtIum6+I2lwT2XNzKy+ekz0EdEhaT7JaJom4JqIWCtpXrp9UW/LFlN1M9uddDVk0IrV03XVanKNo4+IFcCKinVVE3xEzO6prJmVy9ChQ9m8ebOnKq6zzvnos+P08/CdsWZWs1GjRtHe3o4HUtRf5xOmesOJ3sxqttdee9V8m77Vj2evNDMrOSd6M7OSc6I3Mys5J3ozs5JzojczKzknejOzknOiNzMrOSd6M7OSc6I3Mys5J3ozs5JzojczKzknejOzknOiNzMrOSd6M7OSy5XoJZ0s6VFJ6yUtqLJ9pqTVklalD/h+Y2bbRklrOrcVWXkzM+tZj/PRS2oCFgInkjzsu03S8oh4OLPbD4DlERGSJgLfBMZntk+PiGcKrLeZmeWUp0XfCqyPiA0R8RKwFJiZ3SEi/hgvP8hwGND7hxqamVld5En0BwFPZpbb03U7kfQ2SeuA7wL/mNkUwK2S7pc0t5bKmplZ7+VJ9NWe9LtLiz0ilkXEeOA04JLMpmkRMQU4BbhQ0puqBpHmpv37K/3cSTOz4uRJ9O3AwZnlUcCmrnaOiDuBwyTtny5vSv99ClhG0hVUrdziiGiJiJbm5uac1Tczs57kSfRtwDhJYyUNAc4Glmd3kHS4JKWvpwBDgM2Shkkanq4fBswAHiryDZiZWfd6HHUTER2S5gO3AE3ANRGxVtK8dPsi4HTgnZK2As8DZ6UjcA4ElqXfAYOB6yLi5jq9FzMzq6LHRA8QESuAFRXrFmVefxr4dJVyG4BJNdbRzMxq4DtjzcxKzonezKzknOjNzErOid7MrOSc6M3MSs6J3sys5JzozcxKzonezKzknOjNzErOid7MrOSc6M3MSs6J3sys5JzozcxKzonezKzknOjNzErOid7MrORyJXpJJ0t6VNJ6SQuqbJ8pabWkVekDvt+Yt6yZmdVXj4leUhOwEDgFOAqYJemoit1+AEyKiMnAPwJX96KsmZnVUZ4WfSuwPiI2RMRLwFJgZnaHiPhjRES6OAyIvGXNzKy+8iT6g4AnM8vt6bqdSHqbpHXAd0la9bnLmplZ/eRJ9KqyLnZZEbEsIsYDpwGX9KYsgKS5af/+yqeffjpHtczMLI88ib4dODizPArY1NXOEXEncJik/XtTNiIWR0RLRLQ0NzfnqJaZmeWRJ9G3AeMkjZU0BDgbWJ7dQdLhkpS+ngIMATbnKWtmZvU1uKcdIqJD0nzgFqAJuCYi1kqal25fBJwOvFPSVuB54Kz04mzVsnV6L2ZmVkWPiR4gIlYAKyrWLcq8/jTw6bxlzcyscXxnrJlZyTnRm5mVnBO9mVnJOdGbmZWcE72ZWck50ZuZlZwTvZlZyTnRm5mVnBO9mVnJOdGbmZWcE72ZWck50ZuZlZwTvZlZyTnRm5mVnBO9mVnJOdGbmZVcrkQv6WRJj0paL2lBle3nSlqd/twtaVJm20ZJayStkrSyyMqbmVnPenzClKQmYCFwIsnDvtskLY+IhzO7/Rw4PiKelXQKsBg4JrN9ekQ8U2C9zcwspzwt+lZgfURsiIiXgKXAzOwOEXF3RDybLt4LjCq2mmZm1ld5Ev1BwJOZ5fZ0XVfeDXwvsxzArZLulzS391U0M7Na5Hk4uKqsi6o7StNJEv0bM6unRcQmSQcAt0laFxF3Vik7F5gLMHr06BzVMjOzPPK06NuBgzPLo4BNlTtJmghcDcyMiM2d6yNiU/rvU8Aykq6gXUTE4ohoiYiW5ubm/O/AzMy6lSfRtwHjJI2VNAQ4G1ie3UHSaODbwHkR8Vhm/TBJwztfAzOAh4qqvJmZ9azHrpuI6JA0H7gFaAKuiYi1kual2xcBHwP2A74sCaAjIlqAA4Fl6brBwHURcXNd3omZmVWVp4+eiFgBrKhYtyjzeg4wp0q5DcCkyvVmZtY4vjPWzKzknOjNzErOid7MrOSc6M3MSs6J3sys5JzozcxKzonezKzknOjNzErOid7MrOSc6M3MSs6J3sys5JzozcxKzonezKzknOjNzErOid7MrOSc6M3MSi5Xopd0sqRHJa2XtKDK9nMlrU5/7pY0KW9ZMzOrrx4TvaQmYCFwCnAUMEvSURW7/Rw4PiImApcAi3tR1szM6ihPi74VWB8RGyLiJWApMDO7Q0TcHRHPpov3AqPyljUzs/rKk+gPAp7MLLen67rybuB7fSxrZmYFy/NwcFVZF1V3lKaTJPo39qHsXGAuwOjRo3NUy8zM8sjTom8HDs4sjwI2Ve4kaSJwNTAzIjb3pixARCyOiJaIaGlubs5TdzMzyyFPom8DxkkaK2kIcDawPLuDpNHAt4HzIuKx3pQ1M7P66rHrJiI6JM0HbgGagGsiYq2keen2RcDHgP2AL0sC6Ehb51XL1um9mJlZFXn66ImIFcCKinWLMq/nAHPyljUzs8bxnbFmZiXnRG9mVnJO9GZmJedEb2ZWck70ZmYl50RvZlZyTvRmZiXnRG9mVnJO9GZmJedEb2ZWck70ZmYl50RvZlZyTvRmZiXnRG9mVnJO9GZmJedEb2ZWcrkSvaSTJT0qab2kBVW2j5d0j6QXJV1csW2jpDWSVklaWVTFzcwsnx6fMCWpCVgInEjysO82Scsj4uHMbr8D3gec1sVhpkfEMzXW1czM+iBPi74VWB8RGyLiJWApMDO7Q0Q8FRFtwNY61NHMzGqQJ9EfBDyZWW5P1+UVwK2S7pc0tzeVMzOz2uV5OLiqrItexJgWEZskHQDcJmldRNy5S5DkS2AuwOjRo3txeDMz606eFn07cHBmeRSwKW+AiNiU/vsUsIykK6jafosjoiUiWpqbm/Me3szMepAn0bcB4ySNlTQEOBtYnufgkoZJGt75GpgBPNTXypqZWe/12HUTER2S5gO3AE3ANRGxVtK8dPsiSa8GVgL7ANslfQA4CtgfWCapM9Z1EXFzXd6JmZlVlaePnohYAayoWLco8/o3JF06lf4ATKqlgmZmVhvfGWtmVnJO9GZmJedEb2ZWck70ZmYl50RvZlZyTvRmZiXnRG9mVnJO9GZmJedEb2ZWck70ZmYl50RvZlZyTvRmZiXnRG9mVnJO9GZmJedEb2ZWck70ZmYllyvRSzpZ0qOS1ktaUGX7eEn3SHpR0sW9KWtmZvXVY6KX1AQsBE4heTzgLElHVez2O+B9wGf7UNbMzOooT4u+FVgfERsi4iVgKTAzu0NEPBURbcDW3pY1M7P6ypPoDwKezCy3p+vyqKWsmZkVIE+iV5V1kfP4uctKmitppaSVTz/9dM7Dm5lZT/Ik+nbg4MzyKGBTzuPnLhsRiyOiJSJampubcx7ezMx6kifRtwHjJI2VNAQ4G1ie8/i1lDUzswIM7mmHiOiQNB+4BWgCromItZLmpdsXSXo1sBLYB9gu6QPAURHxh2pl6/RezMysih4TPUBErABWVKxblHn9G5JumVxlzcyscXxnrJlZyTnRm5mVnBO9mVnJOdGbmZWcE72ZWck50ZuZlZwTvZlZyTnRm5mVnBO9mVnJOdGbmZWcE72ZWck50ZuZlZwTvZlZyeWavdLqY8yC7/Zq/42X/l2damJmZeYWvZlZyTnRm5mVXK5EL+lkSY9KWi9pQZXtkvTFdPtqSVMy2zZKWiNplaSVRVbezMx61mMfvaQmYCFwIsnDvtskLY+IhzO7nQKMS3+OAa5M/+00PSKeKazWZmaWW54WfSuwPiI2RMRLwFJgZsU+M4GvR+Je4C8ljSy4rmZm1gd5Ev1BwJOZ5fZ0Xd59ArhV0v2S5va1omZm1jd5hleqyrroxT7TImKTpAOA2ySti4g7dwmSfAnMBRg9enSOapmZWR55WvTtwMGZ5VHAprz7RETnv08By0i6gnYREYsjoiUiWpqbm/PV3szMepQn0bcB4ySNlTQEOBtYXrHPcuCd6eib1wPPRcSvJQ2TNBxA0jBgBvBQgfU3M7Me9Nh1ExEdkuYDtwBNwDURsVbSvHT7ImAF8BZgPfBn4Py0+IHAMkmdsa6LiJsLfxdmZtalXFMgRMQKkmSeXbco8zqAC6uU2wBMqrGOZmZWA98Za2ZWck70ZmYl50RvZlZyTvRmZiXn+ehLrrdz3oPnvTcrG7fozcxKzonezKzknOjNzErOid7MrOSc6M3MSs6J3sys5Dy80grhYZxmuy8nehtQGvWF0ts4/tKy3ZkTvVk/8VmQNYoTvVnJ+QvFfDHWzKzkcrXoJZ0MfIHkCVNXR8SlFduVbn8LyROmZkfEz/KUNbNy8JnD7qvHRC+pCVgInEjyEPA2Scsj4uHMbqcA49KfY4ArgWNyljUzy80XynsvT9dNK7A+IjZExEvAUmBmxT4zga9H4l7gLyWNzFnWzMzqKE/XzUHAk5nldpJWe0/7HJSzrJnZbmV3Hcbb1zhKnuvdzQ7SO4CTImJOunwe0BoRF2X2+S7wqYj4cbr8A+CfgEN7Kps5xlxgbrp4JPBoL97H/sAzvdi/rxxn94zhOLtvDMdpXIxDIqK52oY8Lfp24ODM8ihgU859huQoC0BELAYW56jPLiStjIiWvpR1nPrGKdN7KVucMr2XssUpOkaePvo2YJyksZKGAGcDyyv2WQ68U4nXA89FxK9zljUzszrqsUUfER2S5gO3kAyRvCYi1kqal25fBKwgGVq5nmR45fndla3LOzEzs6pyjaOPiBUkyTy7blHmdQAX5i1bB33q8nGchsQp03spW5wyvZeyxSk0Ro8XY83MbGDzFAhmZiXnRG9mVnIDLtFLGt3fdbD+I2mfbrY17P+GpAEz86ukqd1sO6/OsfeSdLSkA+oZx7o34ProJf0sIqY0IM4Xu9seEe+rU9z9gDcBv4yI+ws65tu72x4R3y4iThrrAJIL838FBPAw8OWI+G1Bx9/x+Uv6QUS8udq2gmL9NzA/In5Rsf5vgcsj4q+LilUl9v7A5ijgD1TSauAnwD9HxO/TdX8NfBn4XUScVmuMTKxFwBXpyLx9gXuAbcAI4OKI+M8CYw0mmWdrfLrqEeDmiOgo6Pjv7G57RHy9oDjvAe6IiMfTCSKvAU4HNpKZILIWA6ZVkqEGxZkHPAR8k+Qmr7rElXQTsCAiHkrnB/oZsBI4TNLiiLi8gDA3AqvSH9j5vQRQSKKXNA24DlgCfD2NMwX4qaRzI+InRYTJvB7RzbYiLAVul/RV4DNAM3A5MBp4V1FB0ntPLgV+B1wCfIPkzshBkt4ZETfXGGIK8BHgAUmXABNIhkN/OCJuqvHYlY6LiHnp6/OBxyLiNEmvBr4HFJLoJb0GuB34NfAAyWf/VuBzkqZHRNUbM3up2pmQgFNJpncpJNED7yf5mwGYBUwExgJHk8z8e1zNESJiQP0ATwFf7OqnwDj7kST724HbgDnAq+rwftZmXv8LyeRwAMOB1QXFeBtJ0loJ/C/g8Dp9NvcCR1dZPxn4aUExflbtdbXlguLtC1xFco/IL0im6VDBMVYCM4B3AM8Cr0/XjwceKDDOR4DtJHeyv6ZO/wceyLz+LkmLdJdtBcRZAnygyvr3AV+rw/sS8A/AGuB6YGKBx16VeX0d8P7MciH/pwdii/55oJAuje5ExGZgEbBI0kEk37RrJX00Ir5RYKitmddvBr6Sxt8iaXsRASJiGbBM0jCS2UM/l3YR/WtE/KiIGKl9IuKBKvFXSRpeUIwDJH2I5A+v8zXpctV5Pmp0FMksrPcBLcCBJGfCW7sr1EuDI+JWAEmfiGQGWCJiXXImXxtJh5F002wDXkvS3XGnpE9GxP+tOcDOfi/prcCvgGnAu9M6DAb2LjDO6yNiduXKiPiipN7Mk9WttN6zgQ8DPwXOiIjCjp/anp7NP0uSAz6Z2VbI72wgJvrNEfG1RgWTNIUkyZ9IcupZ9JfMk5IuImllTQFuTuPuDexVcKwXgOeAP5B0Pwwt+PiS9KqIeLZi5QiKu/D/FZKzncrXAFcXFAMASVeTfCYXRMQ96Rflx4EHJX2gMzkXIPuF/nzFtiIuot1C0j14Y7r8qKRvAp+XNCciphUQo9N7Sc6uX03S4v5Nuv7NJC38olT+nrL+XEQASReSdKv8ADg5Kq7VFOhjJGd1TcDySGcPkHQ8sKGIAAPxYuy9EfH6KuunAedERNU7dPsQ5+MkfX6PkHR7FHaRpyLOAcAngJHAwkzLbjrwuoj4bAExppN8WbUC3weWRsTKWo9bJc5c4D3AxSTXGgBeB3yaZPqLq4qOWU+SPkjSHbitYv0EkgvMtfedJsfbBvyJ5Kxkb15OVAKGRkRNX/iSXhkRf+xi299GxPdrOX5/kLSB5P/ZLpuAz0TEYQXE2E7SVfw0O3/himRCgIm1xsjEGgwMzzaSJP0F0BQRW2o+/kBL9FmSJgPnAGcCPwe+HRFXFHTs7STfpp0th85fVOEfcr2l72U18GOS97HThx4FjiBKT9v/iWTUDcBa4D8i4r8LOv5fAYdFxPJ0+TKSfnSAL0UBIxQq4tV1FFF/SbtzZgFnR4GjhyRdwc7/v4Jkut3bI53GvKA43XY5RcT5BcSYR3KGXS1JnhURn6k1RhdxBUwnyW2nRsSBNR9zoCV6SUeQzII5C9hMcmHk4og4pOA43R6vqNO4dAhflx9CRPx9ATFm9xCjYV1htUp/X5+KiLvT5YdJLjD/BXB6FDtUMDuK6H5eHkX0LqCoUUQNk/YDn0WSQCYCnyJpHK0pMEa10UgjSBpj10cxo8h6qsOBRXwRp2daPwLOi4hfVWwrfJi3pGNIPpu3kfzOLiTpynm224J5jj0AE/124C7g3RGxPl23ISIObVD8JpJW0LUFHe/47rYXfLG0rqq05nZSxJmDKubpznblSfpxRLyx1hjZYwP/o/ICc3omeVVEDIinpaXjtGeRPA/im+nPf0XE2AbWYW/g7og4uk7H35dk7Pk5wGsj4qACjvkAyUXsjwEfiogbstuKei+SPknyRfhLkuGny4CVRX4+A/Fi7OkkLfrbJd1M0n9e+Bh3JXdgXkgyXnY5yRDL+ST9gquAQhJ9NpFLak7XPV3EsTPHrftZQ6rwfv8qdhq9U3G9pui7LxsxiqgRFpLcuHRO57UZSQ1t4UXE80WMIMpKvzz+niS5TyH5v3EacGdBISIiviLpR8C1kt4CXBgRf6aYi+Sd5pI8Ue9K4KaIeKHoz2fAJfqKoYKnAR8EDpR0JbCswJEQ3yAZ7nQPyRj6j5A8MWtmRKwqKAYAkv4NuIjkC2uQpA6Suws/UVCImi/o5nRkRPxLnWNsknRMRPw0uzK96aiIm2QqDlv3UUSNMIqkgfR5SQeStOiLHtHVpfRC43kkI8uKOua1JHeQ3wp8CfghsD4i7igqRqeIeEzSG4D/TXLTWbd3zPbBq0nuo5gFXC7pdmBvSYMLGwBS60D8Rv8AS6qsG0EyrOuHBcZZk3ndRJL0h9fh/XyQ5GxhbGbdoSRD4j7YgN/ntAKPVfgNS1VitJJceP83kjsUTwX+PV3XWnCsuSRPSTuepLU4HDiBZDz1e+v9XuvxuZAk/YtJrjk8AvyfgmNtIRm+uyXz81uSL5fCbtICHiQZYHAxcHC6bkPB7+WBKutOIBmksaVOn9VQ4AzgW+nv7boijjsQ++gbNdfNTnHqFTftBzwxIp6pWN8M3BoF9AOm1xXOJOmGujmS6RbeSnIn7t5FxEjjPEjyh1D1HD0ifldQnAPZeSTMWpIvy1lR0PDaTKy6jiJqhK76k9OBDbMi4uP9UK2aSRpP0m1zFskwyPHAhHh57H6txz8tIr5TZf2rSL7oLy0iTjfxhwNvjwIGSwzERL+O5BSnq2RSyPC6zNhm2Hl8c+fwyi5nUexlnIeii+Ft3W3rZYwlJA9pvw84huRW/jeQ3ETznVqPn4nzIskdkdU+m4iCL5hLOprk/0Ln8NpvRcSXioxRBpLagc93tT0iutzWx3iVk409DNwSdbgPJROzhSTpnwG0R8Sx9YpVNL18d3dVRXw+A66PnqRV+jm6SCbA3xQRJCKaijhODi/1cVtvtJDMzbFd0lCScc2HF9XyyXi4qLODrnQxvFYRMb0OsT7WzeaIiEuKjlknTcAr6fpvpjDqerKxz6u4ycZ2EclF5pWSFpB88Q8k2Qv77yWZW6lTIZ/PQGzRVz0NHagqzhx22kQBd0WmMRrWDdXVZ1Pg2OaGDa+V9OEqq4eRzN+yX0S8suiY9dCo7s401hKSSbour1j/PpI7vQuZ9bOLUXEXkvTZPxgRM4uI02j1ym8DsUVfKg06cxivZE5ySL5ADsssE8Xd5fuF7ELl2GaSP8paNWR4LUBEfK7zddpf+n6SqXeXkpxVDhSNmtobGjTZGF2PijstCh4V12B1aXkPxET/0eyCpL2AvwZ+FRFP9U+VdnuTSGZdfLJi/SEUOCQxIpbUe2xzNG54LbBjKOWHgHOBrwFTooA7FRvszT3vUpi6TzaWOjQiJgCdk889A4yOAuaFKaOBmOjfLulXUeUJNpIKfYJNiVwG/Evs+qSk5nTbqUUEafDY5j+R3LR2bZqM3wEsSGMXQtJ/AG8HFpOM5qg6MdjurqjRTjntq+pPNBNQyACG1I5poiNim6SfD9QkL2kNL7fkD8+ebUMxZ9wDsY9+bUT8Vfr6A8AJkXmCTZn674vSw8ieNZ0towLiPEjyB/11knlNnmzk9BRFS68HvAh0UH32wiITVymoAZONpXEaMiquESSNo5sz7s5rUbUYiC367EiUE4EbACLiN0XfYl0i3c07X9jDICJiUmZs8/clPQUMl/TqOozwqbuIGEh3v+4WikrkOeI0alRcI9T9jHsgJvrfqzFPsCmTNknviYivZFdKejcFP0glItaRTAL1sczY5vskDaixzdY3PUwPEFHs09nKYkxErK5cGRErJY0pIsBA7Lo5gpefYHN5RCxJ158EzIiIakPi9mjpnaTLSM6GOhN7C8kohbfVu7UtaQhwZkT8v3rGsf6nZAbTXVaTPlA7IgZi47KuJK2PiMN7u61XMQZaou+Okse7Xd7f9dhdKXnSVGdf/dqI+GHBxy/l2GbrGyV9qeeSjJR7GPhktZbrnk7Sf5LM01XtjHtGRJxVc4ySJfpfRsTo/q7HnkrSf/Hy2OY3A68iOWt4/wAf22y9oF0fqP2pKP6B2qXRiDPusiX6JyPi4P6ux54qO4InnUjNY5v3MNr5gdqXVl5gtK7V84y7bIneLfp+1KipFmz3pQY+UNvyG3CJXtIWqt8mLJIpd32xp5+UaWyz9Y0a9Kxl650Bl+ht9yVpr4jY2vOeZtZIbv1akX5KMr+N7aF6OOP2WV0/caK3IvnW5D1cRAykh6bvMZzorUjN3T0tp+gnGZlZPk70VqTunmRkZv3EF2OtMB5OabZ78ux8ViS35M12Q27RW2HSB0OfCRwOrAG+GhEd/VsrM3Oit8JIup7kyT93AacAv4iI9/dvrczMid4KUzHXzWDgPvfZm/U/99FbkbLP8XSXjdluwi16K4znujHbPTnRm5mVnLtuzMxKzonezKzknOhtjyHpfZIekXRtL8uNkXROveplVm9O9LYnuQB4S0Sc28tyY4BeJ/r0cYpm/c6J3vYIkhYBhwLLJf2rpGsktUl6QNLMdJ8xku6S9LP059i0+KXAcZJWSfqgpNmSvpQ59k2STkhf/1HSJyT9FHiDpH+QdF9a9ionf+sPTvS2R4iIecAmYDowDPhhRExNl/9D0jCSZ52emN7kdRbwxbT4AuCuiJgcEZf1EGoY8FBEHANsTo8zLSImA9uA3p5NmNXM0xTbnmgG8PeSLk6XhwKjSb4IviRpMklSPqIPx94GfCt9/WbgdUCbJEjuK3iq79U26xsnetsTCTg9Ih7daaX078BvgUkkZ7svdFG+g53PhodmXr8QEdsycb4WEf9cRKXN+spdN7YnugW4SGkzW9LR6fp9gV9HxHbgPJIHqQBsAbKPyNsITJY0SNLBQGsXcX4AnCHpgDTOCEmHFPpOzHJworc90SXAXsBqSQ+lywBfBt4l6V6SbpvO6RxWAx2SHpT0QeAnwM9JpmL+LPCzakEi4mHgfwK3SloN3AaMrM9bMuuap0AwMys5t+jNzErOid7MrOSc6M3MSs6J3sys5JzozcxKzonezKzknOjNzErOid7MrOT+P72IkR8d7ozpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#? RandomForestRegressor\n",
    "imp = pd.DataFrame({'feature': X_train.columns,'importance': model.feature_importances_})\n",
    "imp = imp.sort_values('importance', ascending=False).set_index('feature')\n",
    "\n",
    "print(imp)\n",
    "\n",
    "imp.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4\n",
    "- Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "- Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "- С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.\n",
    "- Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков. \n",
    "- Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма: pd.options.display.max_columns = 100.\n",
    "- Просмотрите первые 10 строк датафрейма df.\n",
    "- Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "- Создайте объект Series под названием y из столбца Class.\n",
    "\n",
    "Продолжение ниже по коду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    0.998273\n",
      "1    0.001727\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "ls = pd.Series(df.value_counts('Class', normalize=True))\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.loc[:, 'Class'].copy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  0.090794 -0.551600 -0.617801   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425 -0.166974  1.612727  1.065235   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  0.207643  0.624501  0.066084   \n",
       "3       1.247203  0.237609  0.377436 -1.387024 -0.054952 -0.226487  0.178228   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  0.753074 -0.822843  0.538196   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n",
       "284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19  \\\n",
       "0      -0.991390 -0.311169  1.468177 -0.470401  0.207971  0.025791  0.403993   \n",
       "1       0.489095 -0.143772  0.635558  0.463917 -0.114805 -0.183361 -0.145783   \n",
       "2       0.717293 -0.165946  2.345865 -2.890083  1.109969 -0.121359 -2.261857   \n",
       "3       0.507757 -0.287924 -0.631418 -1.059647 -0.684093  1.965775 -1.232622   \n",
       "4       1.345852 -1.119670  0.175121 -0.451449 -0.237033 -0.038195  0.803487   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n",
       "284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n",
       "284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n",
       "284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n",
       "284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26  \\\n",
       "0       0.251412 -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
       "1      -0.069083 -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
       "2       0.524980  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
       "3      -0.208038 -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
       "4       0.408542 -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n",
       "\n",
       "             V27       V28  Amount  \n",
       "0       0.133558 -0.021053  149.62  \n",
       "1      -0.008983  0.014724    2.69  \n",
       "2      -0.055353 -0.059752  378.66  \n",
       "3       0.062723  0.061458  123.50  \n",
       "4       0.219422  0.215153   69.99  \n",
       "...          ...       ...     ...  \n",
       "284802  0.943651  0.823731    0.77  \n",
       "284803  0.068472 -0.053527   24.79  \n",
       "284804  0.004455 -0.026561   67.88  \n",
       "284805  0.108821  0.104533   10.00  \n",
       "284806 -0.002415  0.013649  217.00  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collist = df.columns.tolist()\n",
    "collist.remove('Class')\n",
    "X = df.loc[:, collist].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4 продолжение\n",
    "- Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y. У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "- Просмотрите информацию о их форме. Для поиска по сетке параметров задайте такие параметры:\n",
    "- - parameters = [{'n_estimators': [10, 15],\n",
    "- - 'max_features': np.arange(3, 5),\n",
    "- - 'max_depth': np.arange(4, 7)}]\n",
    "- Создайте модель GridSearchCV со следующими аргументами:\n",
    "- - estimator=RandomForestClassifier(random_state=100),\n",
    "- - param_grid=parameters,\n",
    "- - scoring='roc_auc',\n",
    "- - cv=3.\n",
    "- Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "- Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "- Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "- Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "- Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "parameters = [{'n_estimators': [10, 15], \n",
    "               'max_features': np.arange(3, 5),\n",
    "               'max_depth': np.arange(4, 7)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv = GridSearchCV(estimator = RandomForestClassifier(random_state=100),\n",
    "                   param_grid = parameters,\n",
    "                   scoring = 'roc_auc',\n",
    "                   cv = 3,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid=[{'max_depth': array([4, 5, 6]),\n",
       "                          'max_features': array([3, 4]),\n",
       "                          'n_estimators': [10, 15]}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gcv.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99070828e-01, 9.29171738e-04],\n",
       "       [9.99704794e-01, 2.95206364e-04],\n",
       "       [9.99717846e-01, 2.82154033e-04],\n",
       "       ...,\n",
       "       [9.99717846e-01, 2.82154033e-04],\n",
       "       [9.99317795e-01, 6.82204754e-04],\n",
       "       [9.87539019e-01, 1.24609813e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2 = gcv.predict_proba(X_test)\n",
    "y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00092917, 0.00029521, 0.00028215, ..., 0.00028215, 0.0006822 ,\n",
       "       0.01246098])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = y_pred_2[:, 1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462664156037156"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
